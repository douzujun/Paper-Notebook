# (对比学习)Representation Learning with Contrastive Predictive Coding

写在前面由于最近开始在看对比学习的一些相关工作，想把学到的东西记录一下。本文前半部分基于Ankesh Anand关于Contrastive Learning的blog中的内容，想看原文的可以移步下面链接： Contrastive Self-Supervised L…

![img](https://static.zhihu.com/heifetz/assets/apple-touch-icon-152.a53ae37b.png)https://zhuanlan.zhihu.com/p/141172794

## Abstract

这项工作中，提出：通用的**无监督学习方法**，从高维数据中 **提取有用的表示**，我们称之为**对比预测编码 Contrastive Predictive Coding**。

模型的关键：是通过使用强大的 **自回归模型** 预测潜在空间中的未来 来学习这种表示。

We use a **probabilistic contrastive loss（概率对比损失）**：

- 这种损失 诱导 **潜在的空间** 来 捕捉对 **预测未来样本最有用的信息**。

它还通过使用 **nagative sampling**（负采样）使模型易于处理。

虽然以前的大多数工作都 集中在 **评估特定模态** 的 表示上，这里证明了该方法能够学习有用的表示。

## Introduction

学习高级表示：挑战，数据效率，通用性，健壮性；

改进征学习需要解决单一监督任务的特征。

**无监督学习** 最常见的策略之一是预测未来、缺失或上下文信息。预测编码[5，6]的思想是数据压缩信号处理中最古老的技术之一。

最近在无监督学习中的工作已经成功地使用这些想法通过 **预测相邻单词** 来 **学习单词表示**[9]

部分原因是我们 **预测相关值的背景** 通常有条件地依赖于相同的共享高级别潜在信息。通过将这个问题归结为一个预测问题，我们可以自动推断出表征学习感兴趣的特征。

预测相关值的背景 通常有条件地 **依赖于相同的 共享 高级别潜在信息**。

通过将这个问题归结为一个预测问题，我们可以自动推断出表征学习感兴趣的特征。

1. 首先，我们将高维数据压缩到一个更紧凑的潜在嵌入空间中，在该空间中条件预测更容易建模。
2. 其次，我们在这个潜在空间中使用强大的 **自回归模型** 来对未来的许多步骤进行预测。
3. 我们依赖于 **噪声对比估计**（**Noise-Contrastive Estimation** ）的损失函数，其方式类似于自然语言模型中学习单词嵌入的方式，允许对整个模型进行端到端的训练。Contrastive Predictive Coding (CPC)

## Contrastive Predictive Coding (CPC)

### Motivation and Intuitions

我们模型背后的主要直觉 是 学习编码(高维)信号 不同部分之间 潜在共享信息的表示。同时，它会 **丢弃低级信息和更局部的噪声**。

在时间序列和高维建模中，使用下一步预测的方法利用了信号的局部平滑性。当进一步预测未来时，共享信息的数量变得更少，模型需要推断更多的全局结构。

### Contrastive Predictive Coding

1. **非线性编码器 $g_{enc}$ ** 将输入观察序列  **$x_t$**，映射到 **潜在表示序列** **$z_t = g_{enc}(x_t)$ **，potentially with a lower temporal resolution（分辨率）.
2. 自回归模型 **$g_{ar}$** 总结所有 $z_{<=t}$在潜在空间，并产生 **上下文潜在表示**  **$c_t = g_{ar}(z_{<=t})$**
3. 建立一个 密度比（density ratio）模型：
4. 它保留了 $X_{t+k}$ 和 $c_t$ （公式1）之间的相互信息，如下：

![img](https://tcs.teambition.net/storage/31248aff7d5f147255f4772ad5a5f095404c?Signature=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJBcHBJRCI6IjU5Mzc3MGZmODM5NjMyMDAyZTAzNThmMSIsIl9hcHBJZCI6IjU5Mzc3MGZmODM5NjMyMDAyZTAzNThmMSIsIl9vcmdhbml6YXRpb25JZCI6IjVmYjlmYjA4NGE0ZWQxYzc0MjE2ZDQ3ZCIsImV4cCI6MTYxNzkzODkyMCwiaWF0IjoxNjE3MzM0MTIwLCJyZXNvdXJjZSI6Ii9zdG9yYWdlLzMxMjQ4YWZmN2Q1ZjE0NzI1NWY0NzcyYWQ1YTVmMDk1NDA0YyJ9.Aj9PYUVKSFoZMMI2gYfuFUByfn3TIwscJ4NKfIY5HD0)

其中∝代表“成比例”(即，直到乘法常数)。请注意，密度比 f 可以不正规化(不必积分为1)。虽然这里可以使用任何正的真实分数，但是我们使用一个简单的对数双线性模型:

![img](https://tcs.teambition.net/storage/312432d27351232df9e0e1c03cec7da61b8f?Signature=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJBcHBJRCI6IjU5Mzc3MGZmODM5NjMyMDAyZTAzNThmMSIsIl9hcHBJZCI6IjU5Mzc3MGZmODM5NjMyMDAyZTAzNThmMSIsIl9vcmdhbml6YXRpb25JZCI6IjVmYjlmYjA4NGE0ZWQxYzc0MjE2ZDQ3ZCIsImV4cCI6MTYxNzkzOTU3OSwiaWF0IjoxNjE3MzM0Nzc5LCJyZXNvdXJjZSI6Ii9zdG9yYWdlLzMxMjQzMmQyNzM1MTIzMmRmOWUwZTFjMDNjZWM3ZGE2MWI4ZiJ9.EZDH6kK2PAor3NL3NpX9zBSaN7neTXV5jzOFFk7vao8)

这里，线性变换 $W_k^T c_t$ 用于预测，每一步k具有不同的 $W_k$。或者使用 非线性网络 或 递归神经网络。































